\section{Discussion}
\label{sect:discussion}

\subsection{Related Work}
\label{sect:discussions:relatedwork}

\paragraph{Design Rationale} Argumentation in software design has been the subject of the research on so-called \emph{design rationale} (DR), an explicit documentation of the reasons behind decisions made when designing a system or software architecture. Starting already in the 90's with influential issue-driven design methods such as gIBIS and QOC~\cite{shum2006hypermedia},  
DR looks at issues, options and arguments for and against these options in the design of, for example, a software system. Similar to the literature on goal modeling, much of the traditional DR literature provides modeling languages and diagramming tool support for building design rationales. It is in this diagramming functionality that the link with argument diagrams from philosophy, law and AI~\cite{reed2004araucaria,gordon2007visualizing} has been made, where argument diagrams represent reasoning from premises to conclusions. One of the problems of such methods and tools is the cognitive overload that results from having to learn and use such tools at the same time as having to discuss and think about complex software designs [5]. Furthermore, not much of the research on design reasoning has empirically investigated which techniques and how much information designers use in design reasoning, which information is missing, and how the use of design reasoning techniques affects design discussions and eventually the quality of design discourse. More recent research on DR therefore moves away from the idea that all decision have to be explicitly diagrammed and focuses more on empirically investigating how critical reflection can help when designing \cite{razavian2016two,TangEtal2018}, or which parts of the design process are best explicitly documented \cite{falessi2013value}. 

Software design and requirements engineering are very closely related \cite{nuseibeh2001weaving} and hence the insights from the DR literature are directly applicable to RE. The RationalGRL framework essentially incorporates the core ideas from DR into goal-oriented requirements engineering by explicitly including arguments for and against the various options into the goal model. In this respect, we may seem to go against the trend in DR research to focus less on diagramming and more on guidelines for design processes. There are two reasons for this. First, as opposed to DR diagramming, goal modeling is still very much an active area of research \cite{GonccalvesEtal2018} with clear practical applications \cite{NeaceEtal2018}. Second, we note that RationalGRL also includes a development process and critical questions that encourage reflection when thinking about the possible goals and functionality of a system, which connects with the more research ideas on DR \cite{razavian2016two,TangEtal2018}. 

\paragraph{Requirements Engineering} 
There are numerous examples in the RE literature that make mention of arguments, questions or conflicts in some way. Already in 1997, Smith~\cite{Smith:1997:CRF:2737426.2737493} proposed a framework to develop arguments, which relates a model of a proposed software system to a model of its environment, and shows that these together achieve properties described by a model of requirements. In a similar vein, Lockerbie \emph{et al.}~\cite{lockerbie2012exploring} describe procedures that analysts follow to use satisfaction arguments in combination with $i*$. Also, Horkoff and Yu~\cite{horkoff2016interactive} introduce analysis procedures for the $i*$ goal-oriented framework, allowing users to ask questions such as ``what if?'', or ``are certain goals achievable? how? or why not?''. Finally, Hassin and Amyot~\cite{hassine2016questionnaire} analyze the correctness of GRL models by performing statistical analysis on generated questionnaires, which allows for early detection of potential conflicts between stakeholders of the system. The mentioned work, however, does not consider arguments the way RationalGRL does, that is, as explicit opinions of stakeholders. 

A number of approaches in the field of requirements engineering explicitly take into account arguments. One early example comes from Haley \emph{et al.}~\cite{haley2008security}, who use formal logical arguments to show that the system behavior satisfies certain security requirements, and more informal arguments to capture and validate the assumptions underlying the system behavior. This system behavior is defined by the tasks it executes and thus arguments are given for and against system tasks, similar to the way beliefs and counterarguments can be provided for tasks in RationalGRL. What Haley \emph{et al.} leave implicit in their argumentation are the goals of the stakeholders on which the system tasks depend -- they include the goals in their framework and mention that there will often be conflicting goals between stakeholders, but they do not explicitly model them. Furthermore, the argumentative part of their framework does not include formal semantics for resolving conflict between arguments or determining the acceptability of arguments. Yu \emph{et al.}~\cite{yu2015automated} further extend the framework by Haley \emph{et al.}, including algorithms for Dung-style argumentation semantics \cite{Dung1995} and a database of specific ways in which to attack (or mitigate) risks. This extension can be likened to a set of critical questions for risks and security requirements (cf. Yu \emph{et al.}~\cite{yu2015automated} Section 3.1).

Another recent example of the use of arguments in goal-oriented requirements engineering is the work by Murukannaiah \emph{et al.}~\cite{murukannaiah2015}, who propose Arg-ACH, where the beliefs underlying conflicting goals can be made explicit using argumentation. Murukannaiah \emph{et al.} start with the basic technique of Analysis of Competing Hypotheses (ACH), where for conflicting goals, the beliefs that are consistent and inconsistent with these goals are included in a matrix and counted. They then extend this technique into Arg-ACH: instead of just indicating whether a belief is consistent or inconsistent with a goal, each belief becomes an argument for or against the goal, which is then diagrammed using the Carneades tool \cite{gordon2007visualizing}. Belief scores are assigned to arguments, which can be aggregated to provide one's belief in a goal. The arguments for and against goals can be based on argument schemes, and critical questions can be used to find new arguments for or against the goals or the existing arguments. One example provided in the paper is the argument scheme from expert opinion, which allows one to draw conclusions based on expert statements and subsequently question, for example, the objectivity and veracity of the expert using critical questions. Murukannaiah \emph{et al.} conducted an experiment in which they had two groups, one with ACH and one with Arg-ACH, perform an analysis of several conflicting goals regarding security at transport hubs. They found that, while the group that used Arg-ACH took longer, they also covered more possibilities in their belief search and the conclusions were more consistent among the group. 

One other example of argumentation in RE concerns the use of argumentation in requirements elicitation. Ionita \emph{et al.}~\cite{ionita2014argumentation} propose a simple argumentation dialogue game in which risk assessors try to attack each other's arguments for certain risks attached to a system design. Dung's semantics \cite{Dung1995} are then used to determine the risks that are still valid, and those that have been successfully rejected. Elrakaiby \emph{et al.}~\cite{ElrakaibyFSGN17} use argumentation to explain ambiguity. They define when a statement by a client who is being interviewed about the requirements of a system presents an inconsistency or an insufficiency. An inconsistency can be either with the client's previous statements or with the requirement engineer's beliefs. An insufficiency occurs when an analyst needs more information from the client to accept a client's statement.

It is clear from this literature that arguments play a core role in RE. Murukannaiah \emph{et al.}~\cite{murukannaiah2015} show that critical reflection using argument schemes and critical questions -- in the same way that RationalGRL proposes -- improves the quality of the reasoning in the RE process. Elrakaiby \emph{et al.}~\cite{ElrakaibyFSGN17} provide a case study similar to our research, identifying, many counterarguments specifically with respect to realisability, relevance and clarity (cf. CQ2a, CQ3, CQ11 and CQ12 in Table~\ref{table:argument-schemes}). Similar to RationalGRL, the use of Dung-style argumentation semantics to compute the acceptable claims in RE is also advocated by the literature \cite{yu2015automated,ionita2014argumentation,ElrakaibyFSGN17}. 

The current work on RationalGRL puts the insights from the above-mentioned literature in a broader framework. For example, there is a specific focus on security requirements \cite{haley2008security,yu2015automated,ionita2014argumentation} or the reasoning is about single goals or tasks instead of about the wider context as represented in a goal model \cite{haley2008security,yu2015automated,murukannaiah2015,ElrakaibyFSGN17}. RationalGRL provides a generic and extensible framework for arguing about goals and tasks in RE. At the moment, there is only a ``generic argument'' in addition to arguments about goals and tasks. However, new argument schemes and critical questions about, for example, security risks or expert opinions, can be easily added: the metamodel (Figure~\ref{fig:metamodel}) accommodates this and the formal specification in Section~\ref{sect:formalframework} is set up in such a way that extending the definition of argument and adding new algorithms for specific critical questions is easy. 

\paragraph{Goal Modeling} Argumentation has already been included implicitly in existing goal modeling languages. At its core, goal modeling is a process of argumentation: high-level goals are reasons for lower-level goals, tasks and resources. Hence, refinement and decomposition techniques used in requirements engineering \cite{van2001goal} can be seen as explicit argumentation steps in the goal modeling process. Take, for example, CQ2 of PRAS (Section~\ref{sect:background:pras}), which asks whether there are alternative ways of realizing the same goal. Providing an alternative subgoal or task in a goal model is then an explicit argumentative move in the discussion. In this sense, a goal model provides a justification for itself. This idea is also prevalent in our RationalGRL framework: many arguments are in fact GRL elements, and many critical questions can be answered by introducing new GRL elements. However, as was already argued in Section~\ref{sect:introduction} (and also by \cite{Jureta:RE2008}), argumentation produces different, richer and complementary information to the goal model. The goal model is the product of a process of argumentation, and does not include, for example, goals and tasks that were at some point considered but discarded. Furthermore, for goal models, it is only possible to determine the satisfiability of goals given the possible tasks and resources; what cannot be determined is the acceptability of goals, that is, whether they are \emph{acceptable} (cf. Definition 14 given potentially contradictory opinions of stakeholders).  

More explicit rationales for goal models are included in the original GRL specification \cite{Amyot:2010:EGM:1841349.1841356} in the form of \emph{belief} elements, which can be attached to other intentional elements (goals, tasks) using the different links (positive contribution, negative contribution) of GRL. The content of a belief is a textual description, which can explain, for instance, the rationale for including a goal in a model. In this regard, they seem like arguments or reasons for the different elements in a goal model. However, in the literature the precise usage and semantics of belief elements in GRL remain unclear: according to the metamodel \cite{Amyot:2010:EGM:1841349.1841356} they can be connected to other intentional elements (including beliefs) through any type of link, but in the jUCMNav tool there is a separate \emph{belief link} for connecting beliefs to goals and tasks only, and the beliefs are not used in any of the algorithms to compute the satisfiability of goals and tasks. We are also not aware of many examples of the usage of belief elements in the literature. Thus, what it seems like is that GRL belief elements can be understood as metadata that can be attached to an element.  

Ambiguities notwithstanding, there are further advantages of using RationalGRL over GRL with belief elements. For example, in none of the GRL specifications, is it possible to attach beliefs to links between other elements thus it is not possible, for example, to provide a rationale for why some tasks positively contributes to a goal. Furthermore, the RationalGRL arguments follow clear schemes with associated critical questions explicitly tailored towards reasoning about goals and actions or tasks, while beliefs in GRL offer no further guidance as to what kinds of rationales can be given for elements in a goal model. Furthermore, beliefs in GRL seem not to influence the goal model in any way. Arguments in RationalGRL, in contrast, play an important role in forming the resulting goal model: if an element is defeated by an argument, it is not part of the resulting goal model.

\paragraph{Goal Modeling and Argumentation}

There are several contributions to the literature that explicitly relate argumentation-based techniques with goal modeling. The first line of work is by Bagheri and Ensan \cite{bagheri2011consolidating} and Mirbel and Villata \cite{MirbelVillata12} use abstract argumentation frameworks (see Definition~\ref{def:argumentation-framework}) to capture individual goals and the relations between them as modeled in a goal model, so that consistent (i.e., acceptable) subsets of goals can be computed using the relevant argumentation semantics \cite{Dung1995}. For example, if in the goal model there is a conflict between goals $G_1$ and $G_2$, there is an attack between the arguments representing these goals and hence $G_1$ and $G_2$ cannot be in the same extension. Or if there is a dependency link between $G_1$ and $G_2$, then $G_1$ should be in every extension $G_2$ is in and vice versa. AND- and OR-decomposition are also modeled as such, that is, if $G_3$ AND-decomposes into $G_1$ and $G_2$ then $G_1$ and $G_2$ should be in every extension $G_3$ is in, and if $G_3$ OR-decomposes into $G_1$ and $G_2$ then either $G_1$ or $G_2$ should be in every extension $G_3$ is in. 

Modeling goal models as argumentation frameworks allows one to compute the consistent sets of goals and tasks given a goal model. In RationalGRL, we have opted not to provide such an argumentation-theoretic semantics to goal models. The reason for this is that GRL already has quite fine-grained satisfiability semantics \cite{Amyot:2010:EGM:1841349.1841356}, which take into account conflicts, decompositions and dependencies. RationalGRL focuses on what is not captured in the work discussed above \cite{bagheri2011consolidating,MirbelVillata12}, namely the arguments and beliefs underlying a goal model, and the way these arguments and beliefs interact with the elements of the goal model. If desired, however, it would be easy to provide Dung semantics similar to \cite{bagheri2011consolidating,MirbelVillata12} for goal models, as the elements of a goal model are already arguments in RationalGRL (Figure~\ref{fig:metamodel}). 

The contribution most closely related to ours is the work by Jureta \emph{et al.}~\cite{Jureta:RE2008}. Jureta \emph{et al.} propose ``Goal Argumentation Method (GAM)'' to guide argumentation and justification of modeling choices during the construction of goal models. GAM is a high-level decision process, in which alternative solutions for an RE problem are evaluated and compared using argumentation. Jureta \emph{et al.} use a well-known fictitious example of an argumentative discussion regarding a meeting scheduler, in which a goal model is being built by the stakeholders proposing tasks, goals, and alternative solutions for goals. They include clarification as an important step in their GAM process, and discuss various types of clarity problems (vagueness, ambiguity, overgenerality, synonymy) and basic techniques for dealing with them (e.g. thesaurus checks, labeling vague expressions). 

The GAM process is essentially a generic, high-level process for problem solving, not specifically tailored towards goal modeling. In this sense, the RationalGRL Development Process in Figure~\ref{fig:rationalgrl-methodology} can be seen as a more specific version of GAM explicitly meant for goal modeling. The argument schemes and critical questions in RationalGRL provide clearer handles for goal modeling (cf. requirement 4 of our framework, Section~\ref{sect:introduction}). Furthermore, the RationalGRL framework adds full tool support for the goal modeling and reasoning process, which GAM lacks. GAM does contain more specific ways of dealing with different types of clarity problems; in RationalGRL clarification is captured as a single critical question (CQ12, Table~\ref{table:argument-schemes}). However, as argued above further critical questions can easily be added to RationalGRL if needed.

Jureta \emph{et al.}'s framework also includes an argumentation part, where reasons (justifications) for conclusions are given as formal structured arguments\footnote{Informally, a structured argument is similar to the PRAS argument in Section~\ref{sect:background:pras}, i.e., $a, b \xrightarrow{therefore} c$.}. Arguments and alternatives are then captured as structured arguments or argument diagrams with reasons for or against goals and tasks. Given these arguments the set of undefeated (i.e., acceptable) propositions can be computed to determine which alternative solution to a problem is acceptable. Thus, the arguments and beliefs underlying a goal model and possible alternative modelings are captured as formal arguments. Furthermore, a mapping from goal models to argument diagrams is given, so that it is possible to start arguing about an already existing goal model.

RationalGRL allows for two-way translation between arguments about goals and standard goal models (cf. Section~\ref{sect:formalframework:translation}). In contrast, Jureta \emph{et al.} only provide a mapping from goal models to structured arguments, and the step from structured arguments or argument diagrams to goal models is never formally defined. In previous work on the RationalGRL framework~\cite{vanzee-etal:renext2015,vanZee-etal:er2016}, we extended Jureta \emph{et al.}'s work and translated argument diagrams to GRL models (an automatic translation tool is discussed in~\cite{vanZee-etal:er2016}). This gives us two complex diagrams, an argument diagram and a goal diagram, and a mapping between them. This was, in our opinion, ultimately an unsatisfying solution given the problems and requirements described in Section \ref{sect:introduction}. One problem is that the argument diagram is at least as complex as the GRL diagram. This means that any stakeholder trying to understand the discussion has to parse two complex diagrams containing goals, alternative solutions, tasks, and so forth. RationalGRL overcomes this problem by integrating argumentation and goal modeling in a single modeling language.

\subsection{Future work}
\label{sect:discussion:futurework}

RationalGRL lays down a basic framework for argumentation in requirements engineering, and all aspects of this framework are intended to be fully extensible. We envision a large number of open issues to be explored in future research.

\paragraph{Specific domains}
The argumentation schemes and critical questions presented in this paper are focused only on the core goal modeling process, that is, the discussion about the goals and functionality of an information system. In the RE process, there are many more domain specific discussions that also take place, such as discussions involving expert opinions \cite{murukannaiah2015}, discussions about security requirements \cite{haley2008security,yu2015automated,ionita2014argumentation}, architectural principles \cite{marosin-etal:caise2016}, legal compliance \cite{Ghanavati2013}, and so forth. From a knowledge engineering perspective, including the argument schemes and critical questions associated with these domains in the RationalGRL framework is a time-consuming task. However, from a formal perspective adding new schemes and questions is easy: as already discussed by Bex \emph{et al.}~\cite{bexEtal2003}, critical questions for argument schemes will always lead to either new information being introduced, new information replacing old information, or new information attacking old information. This corresponds to the \textsf{INTRO}, \textsf{REPLACE} and \textsf{DISABLE} operations in the RationalGRL framework, which have been formalized in Algorithms 3-9 in Section~\ref{sect:algorithms}, hence it would be suitable for other types of schemes and questions as well.

\paragraph{Formal argumentation}
The amount of theory from computational argumentation used in this article has been relatively small. Our intention is to create a bridge between the formal theories in argumentation and the practical tools in requirements engineering. Now that the initial framework has been developed, however, it is worth exploring what additional techniques computational argumentation has to offer in more detail. For instance, in our framework we did not include the possibility of expressing preferences between mutually inconsistent arguments (e.g. such as in Figure~\ref{fig:goalmodeling:arg3}). Using the work by Modgil~\cite{modgil2009}, it is possible to provide explicit arguments for preferences, thus allowing us to make a reasoned choice between two options. 

\paragraph{Belief revision} An interesting avenue for further investigation is the theoretical foundation of RationalGRL. Since it is one of our main goals to develop a framework that can be used by practitioners, we developed a formalism that is geared towards implementation using algorithms and a compact propositional logic. However, there is a long strand of research in Artificial Intelligence focusing on developing postulates that characterize how an agent can revise its knowledge base in a rational way~\cite{falappa2009belief}. The most famous postulates are the so-called AGM postulates~\cite{alchourron1985logic}. It would be very interesting to study whether (a variation of) these rationality postulates can be used to characterize the algorithms we have developed in this article, and more generally, what rationality means in our setting. While there is formal work in Artificial Intelligence on the connections between argumentation and belief revision (see e.g. \cite{falappa2009belief}, there is very little work on applying the combination to requirements engineering. The only work we are aware of that deals with his subject is by Gervasi and Zowghi \cite{gervasi2005reasoning}, who use a logical framework for belief revision to detect inconsistencies in software specifications and then revise those specifications so that the inconsistencies are removed. They do not explicitly connect their framework to goal models of goal modeling, however, and do not connect their framework to specific argumentation using schemes in the way RationalGRL does. 

\paragraph{Process and tool support}
The current tool is a prototype that implements the RationalGRL framework in a fairly simple way. That is, by offering the possibility to argue and ask critical questions about a goal model, and then export this goal model for further analysis in jUCMNav. Integration of RationalGRL elements into jUCMNav, or at least creating an import function to import jUCMNav goal models into the tool would allow us to tap into the large amount of research and development that is being carried out with jUCMNav. Furthermore, the tool could be expanded to include the new features described above, such as new argument schemes and reasoning with preferences. 

Additionally, from the user evaluation of the tool, it followed that in order to implement the tool in realistic settings, other ways may have to be found to incorporate arguments in the goal modeling process. One idea is to use the tool for collaborative on-line goal modeling, similar to Github: since the renaming (i.e. replacement) and deletion (i.e. disabling) of elements are all logged, it is easy for a stakeholder to continue working on a model that was made by another stakeholder. Furthermore, critical questions can be included for other stakeholders to answer at a later date. As a formal underpinning of this asynchronous communication between users, it would make sense to capture requirements engineering and software design processes as dialogs between parties~\cite{finkelstein1989multiparty,BlackEtal2013}, which are a natural fit with the question-answer format employed in the RationalGRL framework. Finally, it would make sense to further develop the RationalGRL Development Process. One idea here is to have stakeholders play a card game (similar to the well-known planning poker) with cards that contain critical, reflective questions (cf. \cite{TangEtal2018}).

\paragraph{Empirical validation}
We have performed a coding analysis and found more than 200 occurrences of arguments and questions. We also performed an experiment with 16 participants, testing the usability and usefulness of RationalGRL compared to other goal modeling languages. However, what is still lacking is an industrial-strength case study testing extensively whether, and how, the tools and techniques provided by the RationalGRL framework really improve early phase requirements engineering. The complexity of the domain makes focused experiments difficult, but not impossible. For example, both Murakannaiah \emph{et al.}~\cite{murukannaiah2015} and Tang \emph{et al.}~\cite{TangEtal2018} provided a realistic but bounded problem for their subjects to solve, and similar experiments are imaginable to test RationalGRL: have two groups solve a goal modeling problem, one using only GRL and one using RationalGRL, and examine how they perform. Naturally, the type of problem will greatly influence the outcome. For a simple problem which two people have to solve in an hour, RationalGRL will most likely be of little benefit. However, a more complex problem on which multiple persons have to work asynchronously might benefit from the extra tools offered by RationalGRL. Furthermore, the outcome also depends on which part of the set of tools and techniques offered by RationalGRL is tested: the development process, the tool, or a list of critical questions to serve as reminders during the goal modeling process.

\subsection{Conclusion}
\label{sect:discussion:conclusion}

The process of constructing a goal model involves discussions between requirements engineers and a group of stakeholders. While it is possible to capture part of this discussion process in a goal model, for instance by specifying alternative solutions for a goal, not all of the arguments can be found back in the resulting model. This makes it not only more difficult to understand the model, but other stakeholders may end up having similar discussions throughout the design and development phase as well. Furthermore, the disconnect between goal models and their underlying beliefs and opinions may lead to a poor understanding of the problem and solution domain. 

In order to solve these problems, we present RationalGRL: a framework for integrated goal modeling and argumentation. We extend the well-known goal modeling language GRL with argument schemes and critical questions that can be used to analyze and guide stakeholders' discussions about goal models. Furthermore, we provide formal argumentation semantics for the new RationalGRL language. Our approach, thus, provides a rationalization for the elements of the goal model in terms of underlying arguments, and helps in understanding why parts of the model have been accepted while others have been rejected. In the introduction, we identified five important requirements for our framework. Below, we discuss how the RationalGRL framework meets these requirements.

Our list of argument schemes and critical questions in Table~\ref{table:argument-schemes} was constructed by performing a coding analysis in which we analyzed 153 pages of transcripts of discussions among designers of a traffic simulator information system. In this way, we ensure that the argumentation techniques capture the actual discussions of the stakeholders or designers in the early requirements engineering phase (\textbf{requirement 1}).  

The metamodel of the RationalGRL framework in Figure~\ref{fig:metamodel} clearly specifies the formal traceability links elements of GRL goal model and the underlying arguments. (\textbf{requirement 2}). In addition to this metamodel, we provide formal semantics for RationalGRL by formalizing the GRL language in propositional logic and rendering arguments about a GRL model as a formal argumentation framework~\cite{Dung1995}. We, then, formally capture the link between argumentation and goal modeling as a set of algorithms for applying argument schemes and critical questions about goal models. These formal traceability links allow us to compute the effect of the arguments and counterarguments proposed in a discussion on a GRL model (\textbf{requirement 3}). In other words, we can determine whether the elements of a GRL model are acceptable given potentially contradictory opinions of stakeholders. Thus, we add a new formal evaluation technique for goal models that allows us to assess the \emph{acceptability} of elements of a goal model (in addition to their \emph{satisfiability}~\cite{Amyot:2010:EGM:1841349.1841356}).

One of our main goals is to provide means for RE practitioners to capture the underlying arguments of goal models by using the RationalGRL framework (\textbf{requirement 4}). To this end, we propose a development process, which consists of developing goal models and posing arguments based on schemes in an integrated way. 

Finally, we have implemented the RationalGRL tool, a web-based prototype\footnote{\url{http://www.rationalgrl.com}}, for modeling argument schemes and critical questions and for reasoning about goal models with respect to them (\textbf{requirement 5}). We performed a small empirical evaluation with 16 users. The results indicate that while the cognitive overhead of RationalGRL (or goal modeling in general) is high, combining goal modeling with argumentation is perceived as useful. Furthermore, using a formal semantics to compute which arguments and ultimately goal models are acceptable given the stakeholders' opinions valid argument was perceived as very useful.