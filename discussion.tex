\section{Discussion}
\label{sect:discussion}

\subsection{Related work}
\label{sect:goalmodeling:relatedwork}

\paragraph{Design Rationale} Argumentation in software design has for some time now been the subject of the work on so-called \emph{design rationale} (DR)~\cite{shum2006hypermedia}, an explicit documentation of the reasons behind decisions made when designing a system or software architecture. DR looks at issues, options and arguments for and against these options in the design of, for example, a software system. Similar to the literature on goal modeling, much of the traditional DR literature provides modeling languages and diagramming tool support for building design rationales. It is in this diagramming functionality that the link with argument diagrams from philosophy, law and AI~\cite{reed2004araucaria,gordon2007visualizing} has been made, where argument diagrams represent reasoning from premises to conclusions. More recent work on DR moves away from the idea that all decision have to be explicitly diagrammed and focuses more on empirically investigating how critical reflection can help when designing \cite{razavian2016two,SchriekEtal2016}, or which parts of the design process are best explicitly documented \cite{falessi2013value}. 

Software design and requirements engineering are very closely related \cite{nuseibeh2001weaving} and hence the insights from the DR literature are directly applicable to RE. The work on the RationalGRL framework essentially incorporates the core ideas from DR into goal-oriented requirements engineering by explicitly including arguments pro and con the various options into the goal model, and by proposing a methodology and critical questions that encourage reflection when thinking about the possible goals and functionality of a system. 

\paragraph{Requirements Engineering} There are a number of general approaches in the field of requirements engineering that explicitly take into account arguments. One early example comes from Haley et al.~\cite{haley2008security}, who use formal logical arguments to show that the system behavior satisfies certain security requirements, and more informal arguments to capture and validate the assumptions underlying the system behavior. This system behavior is defined by the tasks it executes and thus arguments are given for and against system tasks, similar to the way beliefs and counterarguments can be provided for tasks in RationalGRL. What Haley et al. leave implicit in their argumentation are the goals of the stakeholders on which the system tasks depend -- they include the goals in their framework and mention that there will often be conflicting goals between stakeholders, but do not explicitly model them. Furthermore, the argumentative part of their framework does not include formal semantics for resolving conflict between arguments or determining the acceptability of arguments. Yu et al.~\cite{yu2015automated} further extend the framework by Haley et al., including algorithms for Dung-style argumentation semantics \cite{Dung1995} and a database of specific ways in which to attack (or mitigate) risks, which can be likened to a set of critical questions for risks and security requirements (cf. Yu et al.~\cite{yu2015automated} Section 3.1). 

Another recent example of the use of arguments in goal-oriented requirements engineering is the work by Murukannaiah et al.~\cite{murukannaiah2015}, who propose Arg-ACH, where the beliefs underlying conflicting goals can be made explicit using argumentation. Murukannaiah et al. start with the basic technique of Analysis of Competing Hypotheses (ACH), where for conflicting goals the beliefs that are consistent and inconsistent with these goals are included in a matrix and counted. They then extend this technique into Arg-ACH: instead of just indicating whether a belief is consistent or inconsistent with a goal, each belief becomes an argument for or against the goal, which is then diagrammed using the Carneades tool \cite{gordon2007visualizing}. Belief scores are assigned to arguments, which can be aggregated to provide one's belief in a goal. The arguments for and against goals can be based on argument schemes, and critical questions can be used to find new arguments for or against the goals or the existing arguments. One example provided in the paper is the argument scheme from expert opinion, which allows one to draw conclusions based on expert statements and subsequently question, for example, the objectivity and veracity of the expert using critical questions. Murukannaiah et al. conducted an experiment in which they had two groups, one with ACH and one with Arg-ACH, perform an analysis of several conflicting goals regarding security at transport hubs. They found that, while the group that used Arg-ACH took longer, they also covered more possibilities in their belief search and the conclusions were more consistent among the group. 

One other example of argumentation in RE concerns the use of argumentation in requirements elicitation. Ionita et al.~\cite{ionita2014argumentation} propose an simple argumentation dialogue game in which risk assessors try to attack each other's arguments for certain risks attached to a system design. Dung's semantics \cite{Dung1995} are then used to determine the risks that are still valid, and those that have been successfully rejected. Elrakaiby et al.~\cite{ElrakaibyFSGN17} use argumentation to explain ambiguity. They define when a statement by a client who is being interviewed about the requirements of a system presents an inconsistency (either with the client's previous statements or with the requirement engineer's beliefs) or an insufficiency, that is, when an analyst needs more information from the client to accept a client's statement. The inconsistencies are then captured as mutually attacking arguments, and the insufficiencies as arguments against the original statements saying that, for example, the functionality expressed in the statement cannot be realised or is irrelevant. Elrakaiby et al. coded the data from 34 requirement elicitation interviews, identifying 39 inconsistencies (i.e. at least two arguments that mutually attack) and 29 insufficiencies (i.e., at least one argument attacking another).

It is clear from this literature that arguments play a core role in RE. Murukannaiah et al.~\cite{murukannaiah2015} show that critical reflection using argument schemes and critical questions -- in the same way that RationalGRL proposes -- improves the quality of the reasoning in the RE process. Elrakaiby et al.~\cite{ElrakaibyFSGN17} provide a case study similar to the current one, identifying, as we did, many counterarguments specifically with respect to realisability, relevance and clarity (cf. CQ2a, CQ3, CQ11 and CQ12 in Table~\ref{table:argument-schemes}). Like in RationalGRL, the use of Dung-style argumentation semantics to compute the acceptable claims in RE is further also advocated by the literature \cite{yu2015automated,ionita2014argumentation,ElrakaibyFSGN17}. 

The current work on RationalGRL puts the insights from the above-mentioned literature in a broader framework. For example, there is a specific focus on security requirements \cite{haley2008security,yu2015automated,ionita2014argumentation} or the reasoning is about single goals or tasks instead of about the wider context as represented in a goal model \cite{haley2008security,yu2015automated,murukannaiah2015,ElrakaibyFSGN17}. RationalGRL provides a generic and extensible framework for arguing about goals and tasks in RE. At the moment, there is only a ``generic argument'' in addition to arguments about goals and tasks. However, new argument schemes and critical questions about for example, security risks or expert opinions, can be easily added: the metamodel (Figure~\ref{fig:metamodel}) accommodates this and the formal specification in Section~\ref{sect:formalframework} is set up in such a way that extending the definition of argument and adding new algorithms for specific critical questions is easy. 

\paragraph{Goal Modeling} Argumentation has been included -- both explicitly and implicitly -- in existing goal modeling languages. For example, the belief element in the original GRL specification \cite{Amyot:2010:EGM:1841349.1841356} is meant to capture the rationales behind the inclusion of goals and tasks in the model. Furthermore, relations between elements in a goal model also provide justifications: high-level goals are reasons for lower-level goals, tasks and resources. Hence, refinement and decomposition techniques used in requirements engineering \cite{van2001goal} can be seen as explicit argumentation steps in the goal modeling process. Take, for example, CQ2 of PRAS (Section~\ref{sect:background:pras}), which asks whether there are alternative ways of realizing the same goal. Providing an alternative sub-goal or -task in a goal model then an explicit argumentative move in the discussion. So in this sense, a goal model provides a justification for itself, particularly if we include belief elements for extra design rationalization. This idea is also prevalent in our RationalGRL framework: many arguments are in fact GRL elements, and many critical questions can be answered by introducing new GRL elements. However, as was already argued in Section~\ref{sect:introduction} (and also by \cite{Jureta:RE2008}), argumentation produces different, richer and complementary information to just the goal model. The goal model is the product of a process of argumentation, and does not include, for example, goals and tasks that were at some point considered but discarded. Furthermore, for goal models it is only possible to determine the satisfiability of goals given the possible tasks and resources; what cannot be determined is the acceptability of goals, that is, whether they are acceptable given potentially contradictory opinions of stakeholders.  

There are several contributions to the literature that relate argumentation-based techniques with goal modeling. The first line of work is by Bagrheri and Ensan \cite{bagheri2011consolidating} and Mirbel and Villata \cite{MirbelVillata12} use abstract argumentation frameworks (see Definition~\ref{def:argumentation-framework}) to capture individual goals and the relations between them as modeled in a goal model, so that consistent (i.e., acceptable) subsets of goals can be computed using the relevant argumentation semantics \cite{Dung1995}. For example, if in the goal model there is a conflict between goals $G_1$ and $G_2$, there is an attack between the arguments representing these goals and hence $G_1$ and $G_2$ cannot be in the same extension. Or if there is a dependency link between $G_1$ and $G_2$, then $G_1$ should be in every extension $G_2$ is in and vice versa. AND and OR decomposition are also modeled thus, that is, if $G_3$ AND-decomposes into $G_1$ and $G_2$ then $G_1$ and $G_2$ should be in every extension $G_3$ is in, and if $G_3$ OR-decomposes into $G_1$ and $G_2$ then either $G_1$ or $G_2$ should be in every extension $G_3$ is in. 

Modeling goal models as argumentation frameworks allows one to compute the consistent sets of goals and tasks given a goal model. In RationalGRL, we have opted not to provide such an argumentation-theoretic semantics to goal models. The reason for this is that GRL already has quite fine-grained satisfiability semantics \cite{Amyot:2010:EGM:1841349.1841356}, which take into account conflicts, decompositions and dependencies. RationalGRL focuses on what is not captured in the work discussed above \cite{bagheri2011consolidating,MirbelVillata12}, namely the arguments and beliefs underlying a goal model, and the way these arguments and beliefs interact with the elements of the goal model. If desired, however, it would be easy to provide Dung semantics similar to \cite{bagheri2011consolidating,MirbelVillata12} for goal models, as the elements of a goal model are already arguments in RationalGRL (Figure~\ref{fig:metamodel}). 

The contribution most closely related to ours is the work by Jureta \emph{et al.}~\cite{Jureta:RE2008}. Jureta \emph{et al.} propose ``Goal Argumentation Method (GAM)'' to guide argumentation and justification of modeling choices during the construction of goal models. GAM is a high-level decision process, in which alternative solutions for an RE problem are evaluated and compared using argumentation. Jureta et al. give a simple made-up example of an argumentative discussion regarding a meeting scheduler, in which a goal model is being built by the stakeholders proposing tasks, goals, and alternative solutions for goals. They include clarification as an important step in their GAM process, and discuss various types of clarity problems (vagueness, ambiguity, overgenerality, synonymy) and basic techniques for dealing with them (e.g. thesaurus checks, labeling vague expressions). Jureta et al. then present the argumentation part of their framework, where reasons (justifications) for conclusions are given as formal structured arguments\footnote{Informally, a structured argument is similar to the PRAS argument in Section~\ref{sect:background:pras}, i.e., $a, b \xrightarrow{therefore} c$.}. Arguments and alternatives are then captured as structured arguments or argument diagrams with reasons for or against goals and tasks. Given these arguments the set of undefeated (i.e., acceptable) propositions can be computed to determine which alternative solution to a problem is acceptable. Thus, the arguments and beliefs underlying a goal model and possible alternative modelings are captured as formal arguments. Furthermore, a mapping from goal models to argument diagrams is given, so that it is possible to start arguing about an already existing goal model.

The GAM process is essentially a generic, high-level process for problem solving, not specifically tailored towards goal modeling. In this sense, the RationalGRL methodology in Figure~\ref{fig:rationalgrl-methodology} can be seen as a more specific version of GAM explicitly meant for goal modeling. The argument schemes and critical questions in RationalGRL provide more clear handles for goal modeling (cf. requirement 4 of our framework, Section~\ref{sect:introduction}).  

In previous work on the RationalGRL framework~\cite{vanzee-etal:renext2015,vanZee-etal:er2016}, we extended Jureta et al.'s work and translated argument diagrams to GRL models\footnote{In \cite{Jureta:RE2008} only a mapping from goal models to structured arguments is given, and the step from structured arguments or argument diagrams to goal models is never formally defined.} (an automatic translation tool is discussed in~\cite{vanZee-etal:er2016}). Thus, we have essentially two complex diagrams, an argument diagram and a goal diagram, and a mapping between them. This was, in our opinion, ultimately an unsatisfying solution given the problems and requirements described in Section \ref{sect:introduction}. One problem is that the argument diagram is at least as complex as the GRL diagram, so any stakeholder trying to understand the discussion has to parse two complex diagrams containing goals, alternative solutions, tasks, and so forth. So the previous iterations of the RationalGRL framework violated requirement 1: argument diagrams do not closely mirror the actual discussions of stakeholders in which ideas are proposed and challenged. 

\subsection{Open issues}
\label{sect:goalmodeling:openissues}

RationalGRL lays down a basic framework for argumentation in requirements engineering, and all aspects of this framework are intended to be fully extensible. We see a large number of open issues to be explored in future research.

\paragraph{Specific Domains}
At the moment, the argumentation schemes and critical questions of RationalGRL are focused only on the core goal modeling process, that is, the discussion about the goals and functionality of an information system. In the RE process, there are many more domain specific discussions that also take place, such as discussions involving expert opinions \cite{murukannaiah2015}, discussions about security requirements \cite{haley2008security,yu2015automated,ionita2014argumentation}, architectural principles \cite{marosin-etal:caise2016}, legal compliance \cite{Ghanavati2013}, and so forth. From a knowledge engineering perspective, including the argument schemes and critical questions associated with these domains in the RationalGRL framework is a time-consuming task. However, from a formal perspective adding new schemes and questions is easy: as already discussed by Bex et al.~\cite{bexEtal2003}, critical questions for argument schemes will always lead to either new information being introduced, new information replacing old information, or new information attacking old information. This corresponds to the \textsf{INTRO}, \textsf{REPLACE} and \textsf{DISABLE} operations in the RationalGRL framework, which have been formalized in Algorithms 3-9 in Section~\ref{sect:algorithms}, which would hence be suitable for other types of schemes and questions as well.

\paragraph{Formal argumentation}
The amount of theory from computational argumentation used in this article has been relatively small. Our intention is to create a bridge between the formal theories in argumentation and the practical tools in requirements engineering. Now that the initial framework has been developed, however, it is worth exploring what additional techniques computational argumentation has to offer in more detail. For instance, in our framework we have not included the possibility of expressing preferences between mutually inconsistent arguments (e.g. like in Figure~\ref{fig:XX}). Using the work by Modgil~\cite{modgil2009}, it is possible to provide explicit arguments for preferences, thus allowing us to make a reasoned choice between two options. 

\paragraph{Tool support}
The current tool is a prototype that implements the RationalGRL framework in a fairly simple way, that is, by offering the possibility to argue and ask critical questions about a goal model, and then export this goal model for further analysis in jUCMNav. Apart from implementing the tool to include the new fatures described above (e.g. new argument schemes, reasoning with preferences), it is also interesting to think about further possibilities. One idea is to use the tool for collaborative on-line goal modeling, similar to Github: because the renaming (i.e. replacement) and deletion (i.e. disabling) of elements are all logged, it is easy for a stakeholder to continue working on a model that was made by another stakeholder. Furthermore, critical questions can be included for other stakeholders to answer at a later date. As a formal underpinning of this asynchronous communication between users, it would make sense to capture requirements engineering and software design processes as dialogs between parties~\cite{finkelstein1989multiparty,BlackEtal2013}, which are a natural fit with the question-answer format employed in the RationalGRL framework. 

\paragraph{Empirical validation}
We have performed a large case study and found more than 200 incidences of arguments and questions. However, what is still lacking is further empirical investigation of whether, and how, the tools and techniques provided by the RationalGRL framework really improve early phase requirements engineering. The complexity of the domain makes focused experiments difficult, but not impossible. For example, Murakannaiah et al.~\cite{murukannaiah2015} provided a realistic but bounded problem for their subjects to solve, and similar experiments are imaginable to test RationalGRL: have two groups solve a goal modelling problem, one using only GRL and one using RationalGRL, and see how they perform. Naturally, the type of problem will greatly influence the outcome. For a simple problem which two people have to solve in an hour, RationalGRL will probably not add much. However, a more complex problem on which multiple persons have to work asynchronously might benefit from the extra tools offered by RationalGRL. Furthermore, the outcome also depends on which part of the set of tools and techniques offered by RationalGRL is tested: the methodology, the tool, or a list of critical questions to serve as reminders during the goal modelling process (cf. \cite{SchriekEtal2016}).








\subsection{Conclusion}

\todo{Marc}{all}{Finish this}

The introduction of this article contains five requirements we identified for our framework. We use the conclusion to discuss how RationalGRL meets our initial requirements.

\paragraph{1. The argumentation techniques should be close to actual discussions stakeholders or designers have.}

We analyze a set of transcripts containing discussions about the architecture of an information system. 

\paragraph{2. The framework must have the means to formally model parts of the discussion process.}
In order to generate goal models based on formalized discussions (requirement 2), we, first, formalize the list of arguments from requirement 1 in an argumentation framework. We formalize the critical questions as algorithms modifying the argumentation framework. We use argumentation techniques from AI in order to determine which arguments are accepted and which are rejected. We propose an algorithm to generate a GRL model based on the accepted arguments. This helps providing traceability links from GRL elements to the underlying arguments (requirement 3).

We implement our framework in an online tool called RationalGRL (requirement 4). The tool is implemented using Javascript. It contains  two parts, goal modeling and argumentation. The goal modeling part is a simplified version of GRL, leaving out features such as evaluation algorithms and key performance indicators. The argumentation part is new, and we develop a modeling language for the arguments and critical questions. The created GRL models in RationalGRL can be exported to jUCMNav~\cite{} %TODO SG: add citation 
 the Eclipse-based tool for GRL modeling, for further evaluation and analysis. 

Our final contribution is a methodology on how to develop goal models that are linked to underlying discussions. The methodology consists of two parts, namely argumentation and goal modeling. In the argumentation part, one puts forward arguments and counter-arguments by applying critical questions. When switching to the goal modeling part, the accepted arguments are used to create a goal model. In the goal modeling part, one simply modifies goal models, which may have an effect on the underlying arguments. This might mean that the underlying arguments are no longer consistent with the goal models.