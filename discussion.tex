\section{Discussion}
\label{sect:discussion}

\subsection{Related work}
\label{sect:discussions:relatedwork}

\paragraph{Design Rationale} Argumentation in software design has for some time now been the subject of the work on so-called \emph{design rationale} (DR)~\cite{shum2006hypermedia}, an explicit documentation of the reasons behind decisions made when designing a system or software architecture. DR looks at issues, options and arguments for and against these options in the design of, for example, a software system. Similar to the literature on goal modeling, much of the traditional DR literature provides modeling languages and diagramming tool support for building design rationales. It is in this diagramming functionality that the link with argument diagrams from philosophy, law and AI~\cite{reed2004araucaria,gordon2007visualizing} has been made, where argument diagrams represent reasoning from premises to conclusions. More recent work on DR moves away from the idea that all decision have to be explicitly diagrammed and focuses more on empirically investigating how critical reflection can help when designing \cite{razavian2016two,SchriekEtal2016}, or which parts of the design process are best explicitly documented \cite{falessi2013value}. 

Software design and requirements engineering are very closely related \cite{nuseibeh2001weaving} and hence the insights from the DR literature are directly applicable to RE. The work on the RationalGRL framework essentially incorporates the core ideas from DR into goal-oriented requirements engineering by explicitly including arguments pro and con the various options into the goal model, and by proposing a methodology and critical questions that encourage reflection when thinking about the possible goals and functionality of a system. 

\paragraph{Requirements Engineering} There are a number of general approaches in the field of requirements engineering that explicitly take into account arguments. One early example comes from Haley et al.~\cite{haley2008security}, who use formal logical arguments to show that the system behavior satisfies certain security requirements, and more informal arguments to capture and validate the assumptions underlying the system behavior. This system behavior is defined by the tasks it executes and thus arguments are given for and against system tasks, similar to the way beliefs and counterarguments can be provided for tasks in RationalGRL. What Haley et al. leave implicit in their argumentation are the goals of the stakeholders on which the system tasks depend -- they include the goals in their framework and mention that there will often be conflicting goals between stakeholders, but do not explicitly model them. Furthermore, the argumentative part of their framework does not include formal semantics for resolving conflict between arguments or determining the acceptability of arguments. Yu et al.~\cite{yu2015automated} further extend the framework by Haley et al., including algorithms for Dung-style argumentation semantics \cite{Dung1995} and a database of specific ways in which to attack (or mitigate) risks, which can be likened to a set of critical questions for risks and security requirements (cf. Yu et al.~\cite{yu2015automated} Section 3.1). 

Another recent example of the use of arguments in goal-oriented requirements engineering is the work by Murukannaiah et al.~\cite{murukannaiah2015}, who propose Arg-ACH, where the beliefs underlying conflicting goals can be made explicit using argumentation. Murukannaiah et al. start with the basic technique of Analysis of Competing Hypotheses (ACH), where for conflicting goals the beliefs that are consistent and inconsistent with these goals are included in a matrix and counted. They then extend this technique into Arg-ACH: instead of just indicating whether a belief is consistent or inconsistent with a goal, each belief becomes an argument for or against the goal, which is then diagrammed using the Carneades tool \cite{gordon2007visualizing}. Belief scores are assigned to arguments, which can be aggregated to provide one's belief in a goal. The arguments for and against goals can be based on argument schemes, and critical questions can be used to find new arguments for or against the goals or the existing arguments. One example provided in the paper is the argument scheme from expert opinion, which allows one to draw conclusions based on expert statements and subsequently question, for example, the objectivity and veracity of the expert using critical questions. Murukannaiah et al. conducted an experiment in which they had two groups, one with ACH and one with Arg-ACH, perform an analysis of several conflicting goals regarding security at transport hubs. They found that, while the group that used Arg-ACH took longer, they also covered more possibilities in their belief search and the conclusions were more consistent among the group. 

One other example of argumentation in RE concerns the use of argumentation in requirements elicitation. Ionita et al.~\cite{ionita2014argumentation} propose an simple argumentation dialogue game in which risk assessors try to attack each other's arguments for certain risks attached to a system design. Dung's semantics \cite{Dung1995} are then used to determine the risks that are still valid, and those that have been successfully rejected. Elrakaiby et al.~\cite{ElrakaibyFSGN17} use argumentation to explain ambiguity. They define when a statement by a client who is being interviewed about the requirements of a system presents an inconsistency (either with the client's previous statements or with the requirement engineer's beliefs) or an insufficiency, that is, when an analyst needs more information from the client to accept a client's statement. The inconsistencies are then captured as mutually attacking arguments, and the insufficiencies as arguments against the original statements saying that, for example, the functionality expressed in the statement cannot be realised or is irrelevant. Elrakaiby et al. coded the data from 34 requirement elicitation interviews, identifying 39 inconsistencies (i.e. at least two arguments that mutually attack) and 29 insufficiencies (i.e., at least one argument attacking another).

It is clear from this literature that arguments play a core role in RE. Murukannaiah et al.~\cite{murukannaiah2015} show that critical reflection using argument schemes and critical questions -- in the same way that RationalGRL proposes -- improves the quality of the reasoning in the RE process. Elrakaiby et al.~\cite{ElrakaibyFSGN17} provide a case study similar to the current one, identifying, as we did, many counterarguments specifically with respect to realisability, relevance and clarity (cf. CQ2a, CQ3, CQ11 and CQ12 in Table~\ref{table:argument-schemes}). Like in RationalGRL, the use of Dung-style argumentation semantics to compute the acceptable claims in RE is further also advocated by the literature \cite{yu2015automated,ionita2014argumentation,ElrakaibyFSGN17}. 

The current work on RationalGRL puts the insights from the above-mentioned literature in a broader framework. For example, there is a specific focus on security requirements \cite{haley2008security,yu2015automated,ionita2014argumentation} or the reasoning is about single goals or tasks instead of about the wider context as represented in a goal model \cite{haley2008security,yu2015automated,murukannaiah2015,ElrakaibyFSGN17}. RationalGRL provides a generic and extensible framework for arguing about goals and tasks in RE. At the moment, there is only a ``generic argument'' in addition to arguments about goals and tasks. However, new argument schemes and critical questions about for example, security risks or expert opinions, can be easily added: the metamodel (Figure~\ref{fig:metamodel}) accommodates this and the formal specification in Section~\ref{sect:formalframework} is set up in such a way that extending the definition of argument and adding new algorithms for specific critical questions is easy. 

\paragraph{Goal Modeling} Argumentation has been included -- both explicitly and implicitly -- in existing goal modeling languages. For example, the belief element in the original GRL specification \cite{Amyot:2010:EGM:1841349.1841356} is meant to capture the rationales behind the inclusion of goals and tasks in the model. Furthermore, relations between elements in a goal model also provide justifications: high-level goals are reasons for lower-level goals, tasks and resources. Hence, refinement and decomposition techniques used in requirements engineering \cite{van2001goal} can be seen as explicit argumentation steps in the goal modeling process. Take, for example, CQ2 of PRAS (Section~\ref{sect:background:pras}), which asks whether there are alternative ways of realizing the same goal. Providing an alternative sub-goal or -task in a goal model then an explicit argumentative move in the discussion. So in this sense, a goal model provides a justification for itself, particularly if we include belief elements for extra design rationalization. This idea is also prevalent in our RationalGRL framework: many arguments are in fact GRL elements, and many critical questions can be answered by introducing new GRL elements. However, as was already argued in Section~\ref{sect:introduction} (and also by \cite{Jureta:RE2008}), argumentation produces different, richer and complementary information to just the goal model. The goal model is the product of a process of argumentation, and does not include, for example, goals and tasks that were at some point considered but discarded. Furthermore, for goal models it is only possible to determine the satisfiability of goals given the possible tasks and resources; what cannot be determined is the acceptability of goals, that is, whether they are acceptable given potentially contradictory opinions of stakeholders.  

There are several contributions to the literature that relate argumentation-based techniques with goal modeling. The first line of work is by Bagrheri and Ensan \cite{bagheri2011consolidating} and Mirbel and Villata \cite{MirbelVillata12} use abstract argumentation frameworks (see Definition~\ref{def:argumentation-framework}) to capture individual goals and the relations between them as modeled in a goal model, so that consistent (i.e., acceptable) subsets of goals can be computed using the relevant argumentation semantics \cite{Dung1995}. For example, if in the goal model there is a conflict between goals $G_1$ and $G_2$, there is an attack between the arguments representing these goals and hence $G_1$ and $G_2$ cannot be in the same extension. Or if there is a dependency link between $G_1$ and $G_2$, then $G_1$ should be in every extension $G_2$ is in and vice versa. AND and OR decomposition are also modeled thus, that is, if $G_3$ AND-decomposes into $G_1$ and $G_2$ then $G_1$ and $G_2$ should be in every extension $G_3$ is in, and if $G_3$ OR-decomposes into $G_1$ and $G_2$ then either $G_1$ or $G_2$ should be in every extension $G_3$ is in. 

Modeling goal models as argumentation frameworks allows one to compute the consistent sets of goals and tasks given a goal model. In RationalGRL, we have opted not to provide such an argumentation-theoretic semantics to goal models. The reason for this is that GRL already has quite fine-grained satisfiability semantics \cite{Amyot:2010:EGM:1841349.1841356}, which take into account conflicts, decompositions and dependencies. RationalGRL focuses on what is not captured in the work discussed above \cite{bagheri2011consolidating,MirbelVillata12}, namely the arguments and beliefs underlying a goal model, and the way these arguments and beliefs interact with the elements of the goal model. If desired, however, it would be easy to provide Dung semantics similar to \cite{bagheri2011consolidating,MirbelVillata12} for goal models, as the elements of a goal model are already arguments in RationalGRL (Figure~\ref{fig:metamodel}). 

The contribution most closely related to ours is the work by Jureta et al.~\cite{Jureta:RE2008}. Jureta et al. propose ``Goal Argumentation Method (GAM)'' to guide argumentation and justification of modeling choices during the construction of goal models. GAM is a high-level decision process, in which alternative solutions for an RE problem are evaluated and compared using argumentation. Jureta et al. use a well-known fictitious example of an argumentative discussion regarding a meeting scheduler, in which a goal model is being built by the stakeholders proposing tasks, goals, and alternative solutions for goals. They include clarification as an important step in their GAM process, and discuss various types of clarity problems (vagueness, ambiguity, overgenerality, synonymy) and basic techniques for dealing with them (e.g. thesaurus checks, labeling vague expressions). 

The GAM process is essentially a generic, high-level process for problem solving, not specifically tailored towards goal modeling. In this sense, the RationalGRL methodology in Figure~\ref{fig:rationalgrl-methodology} can be seen as a more specific version of GAM explicitly meant for goal modeling. The argument schemes and critical questions in RationalGRL provide more clear handles for goal modeling (cf. requirement 4 of our framework, Section~\ref{sect:introduction}). Furthermore, the RationalGRL framework adds full tool support for the goal modeling and reasoning process, something that GAM is lacking. GAM does contain more specific ways of dealing with different types of clarity problems; in RationalGRL clarification is captured as a single critical question (CQ12, Table~\ref{table:argument-schemes}). However, as argued above further critical questions can easily be added to RationalGRL if needed.

Jureta et al.'s framework also includes an argumentation part, where reasons (justifications) for conclusions are given as formal structured arguments\footnote{Informally, a structured argument is similar to the PRAS argument in Section~\ref{sect:background:pras}, i.e., $a, b \xrightarrow{therefore} c$.}. Arguments and alternatives are then captured as structured arguments or argument diagrams with reasons for or against goals and tasks. Given these arguments the set of undefeated (i.e., acceptable) propositions can be computed to determine which alternative solution to a problem is acceptable. Thus, the arguments and beliefs underlying a goal model and possible alternative modelings are captured as formal arguments. Furthermore, a mapping from goal models to argument diagrams is given, so that it is possible to start arguing about an already existing goal model.

RationalGRL allows for two-way translation between arguments about goals and standard goal models (cf. Section~\ref{sect:formalframework:translation}). In contrast, Jureta et al. only provide a mapping from goal models to structured arguments, and the step from structured arguments or argument diagrams to goal models is never formally defined. In previous work on the RationalGRL framework~\cite{vanzee-etal:renext2015,vanZee-etal:er2016}, we extended Jureta et al.'s work and translated argument diagrams to GRL models (an automatic translation tool is discussed in~\cite{vanZee-etal:er2016}). This gives us two complex diagrams, an argument diagram and a goal diagram, and a mapping between them. This was, in our opinion, ultimately an unsatisfying solution given the problems and requirements described in Section \ref{sect:introduction}. One problem is that the argument diagram is at least as complex as the GRL diagram, so any stakeholder trying to understand the discussion has to parse two complex diagrams containing goals, alternative solutions, tasks, and so forth. RationalGRL overcomes this problem by integrating argumentation and goal modeling in a single modeling language.

\subsection{Future work}
\label{sect:discussion:futurework}

RationalGRL lays down a basic framework for argumentation in requirements engineering, and all aspects of this framework are intended to be fully extensible. We see a large number of open issues to be explored in future research.

\paragraph{Specific Domains}
The argumentation schemes and critical questions presented in this paper are focused only on the core goal modeling process, that is, the discussion about the goals and functionality of an information system. In the RE process, there are many more domain specific discussions that also take place, such as discussions involving expert opinions \cite{murukannaiah2015}, discussions about security requirements \cite{haley2008security,yu2015automated,ionita2014argumentation}, architectural principles \cite{marosin-etal:caise2016}, legal compliance \cite{Ghanavati2013}, and so forth. From a knowledge engineering perspective, including the argument schemes and critical questions associated with these domains in the RationalGRL framework is a time-consuming task. However, from a formal perspective adding new schemes and questions is easy: as already discussed by Bex et al.~\cite{bexEtal2003}, critical questions for argument schemes will always lead to either new information being introduced, new information replacing old information, or new information attacking old information. This corresponds to the \textsf{INTRO}, \textsf{REPLACE} and \textsf{DISABLE} operations in the RationalGRL framework, which have been formalized in Algorithms 3-9 in Section~\ref{sect:algorithms}, which would hence be suitable for other types of schemes and questions as well.

\paragraph{Formal argumentation}
The amount of theory from computational argumentation used in this article has been relatively small. Our intention is to create a bridge between the formal theories in argumentation and the practical tools in requirements engineering. Now that the initial framework has been developed, however, it is worth exploring what additional techniques computational argumentation has to offer in more detail. For instance, in our framework we have not included the possibility of expressing preferences between mutually inconsistent arguments (e.g. such as in Figure~\ref{fig:goalmodeling:arg3}). Using the work by Modgil~\cite{modgil2009}, it is possible to provide explicit arguments for preferences, thus allowing us to make a reasoned choice between two options. 

\paragraph{Tool support}
The current tool is a prototype that implements the RationalGRL framework in a fairly simple way, that is, by offering the possibility to argue and ask critical questions about a goal model, and then export this goal model for further analysis in jUCMNav. Integration of RationalGRL elements into jUCMNav, or at least creating an import function to import jUCMNav goal models into the tool would allow us to tap into the large amount of research and development that is being carried out with jUCMNav. Furthermore, the tool could be expanded to include the new features described above, such as new argument schemes and reasoning with preferences. In addition to such extensions, it is interesting to think about new possibilities. One idea is to use the tool for collaborative on-line goal modeling, similar to Github: because the renaming (i.e. replacement) and deletion (i.e. disabling) of elements are all logged, it is easy for a stakeholder to continue working on a model that was made by another stakeholder. Furthermore, critical questions can be included for other stakeholders to answer at a later date. As a formal underpinning of this asynchronous communication between users, it would make sense to capture requirements engineering and software design processes as dialogs between parties~\cite{finkelstein1989multiparty,BlackEtal2013}, which are a natural fit with the question-answer format employed in the RationalGRL framework. 

\paragraph{Empirical validation}
We have performed a case study and found more than 200 incidences of arguments and questions. However, what is still lacking is further empirical investigation of whether, and how, the tools and techniques provided by the RationalGRL framework really improve early phase requirements engineering. The complexity of the domain makes focused experiments difficult, but not impossible. For example, Murakannaiah et al.~\cite{murukannaiah2015} provided a realistic but bounded problem for their subjects to solve, and similar experiments are imaginable to test RationalGRL: have two groups solve a goal modelling problem, one using only GRL and one using RationalGRL, and see how they perform. Naturally, the type of problem will greatly influence the outcome. For a simple problem which two people have to solve in an hour, RationalGRL will most likely be of little benefit. However, a more complex problem on which multiple persons have to work asynchronously might benefit from the extra tools offered by RationalGRL. Furthermore, the outcome also depends on which part of the set of tools and techniques offered by RationalGRL is tested: the methodology, the tool, or a list of critical questions to serve as reminders during the goal modelling process (cf. \cite{SchriekEtal2016}).

\subsection{Conclusion}
\label{sect:discussion:conclusion}

The process of constructing a goal model involves discussions between a requirements engineer and a group of stakeholders. While it is possible to capture part of this discussion process in a goal model, for instance by specifying alternative solutions for a goal, not all of the arguments can be found back in the resulting model. This makes it not only more difficult to understand the model, but other stakeholders may end up having similar discussions throughout the design and development phase as well. Furthermore, the disconnect between goal models and their underlying beliefs and opinions may lead to a poor understanding of the problem and solution domain.  

In order to solve these problems, we present RationalGRL: a framework for integrated goal modeling and argumentation. We extend the well-known goal modeling language GRL with argument schemes and critical questions that can be used to analyze and guide stakeholders' discussions about goal models. Our approach, thus, provides a rationalization for the elements of the goal model in terms of underlying arguments, and helps in understanding why parts of the model have been accepted while others have been rejected. Our list of argument schemes was constructed by performing an extensive case study in which we analyzed a set of transcripts containing more than 4 hours of discussions among designers of a traffic simulator information system. This ensures that the argument schemes we propose are close to actual discussions the stakeholders have (\textbf{requirement 1}).  

The meta-model of the RationalGRL framework clearly specifies the traceability links between the arguments based on the schemes and the GRL models (\textbf{requirement 2}). In addition to this meta-model, we provide formal semantics for RationalGRL by formalizing the GRL language in propositional logic and rendering arguments about a GRL model as a formal argumentation framework~\cite{Dung1995}. We, then, formally capture the link between argumentation and goal modeling as a set of algorithms for applying argument schemes and critical questions about goal models. These formal traceability links allow us to compute the effect of the arguments and counterarguments proposed in a discussion on a GRL model (\textbf{requirement 3}). In other words, we can determine whether the elements of a GRL model are acceptable given potentially contradictory opinions of stakeholders. Thus, we add a new formal evaluation technique for goal models that allows us to assess the \emph{acceptability} of elements of a goal model (in addition to their \emph{satisfiability}~\cite{Amyot:2010:EGM:1841349.1841356}).

One of our main goals is to provide means for RE practitioners to capture the underlying arguments of goal models by using the RationalGRL framework (\textbf{requirement 4}). To this end, we propose a methodology, which consists of developing goal models and posing arguments based on schemes in an integrated way. Finally, we have implemented the RationalGRL tool, a web-based prototype\footnote{\url{http://www.rationalgrl.com}}, for modeling argument schemes and critical questions and for reasoning about goal models with respect to them (\textbf{requirement 5}). 